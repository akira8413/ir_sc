{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a1a8b45d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import csv\n",
    "import os\n",
    "import random\n",
    "\n",
    "SITE_URL = 'http://books.toscrape.com/'\n",
    "DATA_DIRECTORY = os.path.join('.', 'data')\n",
    "BOOKS_DIRECTORY = os.path.join(DATA_DIRECTORY, 'books')\n",
    "IMAGES_DIRECTORY = os.path.join(DATA_DIRECTORY, 'images')\n",
    "\n",
    "\n",
    "def get_page_content(url):\n",
    "\t\"\"\" Get HTML content\n",
    "\n",
    "\tParameters:\n",
    "\t\turl (string): URL of the web page\n",
    "\n",
    "\tReturns:\n",
    "\t\tbs4.BeautifulSoup: Parsed HTML content as BeautifulSoup Object\n",
    "\n",
    "\t\"\"\"\n",
    "\t# Get page content\n",
    "\tpage = requests.get(url)\n",
    "\t# Convert page to Object\n",
    "\treturn BeautifulSoup(page.content, 'html.parser')\n",
    "\n",
    "\n",
    "def get_categories(soup):\n",
    "\t\"\"\" Get the category titles & URLs\n",
    "\n",
    "\tParameters:\n",
    "\t\tsoup (bs4.BeautifulSoup): Parsed HTML content as BeautifulSoup Object from get_page_content()\n",
    "\n",
    "\tReturns:\n",
    "\t\tlist: Formatted like [[title, url], [title, url], ...]\n",
    "\n",
    "\t\"\"\"\n",
    "\ta_list = soup.find(class_='nav-list').find('ul').find_all('a')\n",
    "\tlist_title_and_url = []\n",
    "\tfor a in a_list:\n",
    "\t\t# Text without whitespace & relative category URL formatted\n",
    "\t\tlist_title_and_url.append([a.text.strip(), SITE_URL + a['href']])\n",
    "\treturn list_title_and_url\n",
    "\n",
    "\n",
    "def get_product_page_url(soup, url):\n",
    "\t\"\"\" Get the product page URLs of the entire category page.\n",
    "\tIf there is pagination, it gets the next page and so on.\n",
    "\n",
    "\tParameters:\n",
    "\t\tsoup (bs4.BeautifulSoup): Category page content\n",
    "\t\turl (string): URL of the category page\n",
    "\n",
    "\tReturns:\n",
    "\t\tlist: Books URL\n",
    "\n",
    "\t\"\"\"\n",
    "\t# Get parents elements\n",
    "\tdiv_list = soup.find_all(class_='image_container')\n",
    "\tbooks_url = []\n",
    "\t# Get URL & format it from relative to absolute\n",
    "\tfor div in div_list:\n",
    "\t\tproduct_relative_url = div.find('a')['href']\n",
    "\t\tproduct_url_list = product_relative_url.split('/')[3:]\n",
    "\t\tproduct_url = SITE_URL + 'catalogue/' + '/'.join(product_url_list)\n",
    "\t\tbooks_url.append(product_url)\n",
    "\t# Check if there is next page\n",
    "\ttry:\n",
    "\t\tnext_page = soup.find(class_='pager').find(class_='next').find('a')['href']\n",
    "\texcept AttributeError:\n",
    "\t\tnext_page = ''\n",
    "\tif next_page:\n",
    "\t\t# Format URL by adding next_page\n",
    "\t\turl_in_list = url.split('/')[:-1]\n",
    "\t\tnext_page_url = '/'.join(url_in_list) + '/' + next_page\n",
    "\t\tbooks_url += get_product_page_url(get_page_content(next_page_url), next_page_url)\n",
    "\treturn books_url\n",
    "\n",
    "\n",
    "def download_image(url, file_name, category):\n",
    "\t\"\"\" Download image and save it locally.\n",
    "\n",
    "\tParameters:\n",
    "\t\turl: Image URL\n",
    "\t\tfile_name: To rename the image\n",
    "\t\tcategory: Category name to create separate folder\n",
    "\n",
    "\tReturns:\n",
    "\t\tNone\n",
    "\n",
    "\t\"\"\"\n",
    "\t# Get file extension\n",
    "\timage_extension = '.' + url.split('.')[-1]\n",
    "\t# Get image content in bytes\n",
    "\timage = requests.get(url).content\n",
    "\n",
    "\t# Replace '/' or '\\' to write it into the system\n",
    "\tif os.sep in file_name:\n",
    "\t\tfile_name = file_name.replace(os.sep, ' - ')\n",
    "\t# Replace double quotes because of error at \"ls\" command\n",
    "\tif '\"' in file_name:\n",
    "\t\tfile_name = file_name.replace('\"', '\\'\\'')\n",
    "\tdestination = IMAGES_DIRECTORY + os.sep + category + os.sep\n",
    "\tpath = destination + file_name + image_extension\n",
    "\t# Check if file_name is in th directory & redirect output to /dev/null\n",
    "\tcommand = f'ls \"{path}\" &> /dev/null'\n",
    "\tif os.system(command) != 512:\n",
    "\t\t# Change file_name\n",
    "\t\tnumber = ''\n",
    "\t\t# Generate 3 random digit to add them to file_name\n",
    "\t\tfor i in range(3):\n",
    "\t\t\tnumber += str(random.randint(0, 9))\n",
    "\t\tfile_name += number\n",
    "\t\tpath = destination + file_name + image_extension\n",
    "\t# Open new file in \"write byte\" mode\n",
    "\twith open(path, 'wb') as file:\n",
    "\t\tfile.write(image)\n",
    "\n",
    "\n",
    "def extract_data(soup, book_category):\n",
    "\t\"\"\" Try to extract all data. If nothing there, assign default value.\n",
    "\n",
    "\tParameters:\n",
    "\t\tsoup (bs4.BeautifulSoup): Product page content\n",
    "\t\tbook_category (string): Category name for assign category\n",
    "\n",
    "\tReturns:\n",
    "\t\tlist: All needed information\n",
    "\n",
    "\t\"\"\"\n",
    "\tdefault_value = 'No Value'\n",
    "\t# Get next td node after element\n",
    "\ttry:\n",
    "\t\tuniversal_product_code = soup.find(text='UPC').findNext('td').string\n",
    "\texcept AttributeError:\n",
    "\t\tuniversal_product_code = default_value\n",
    "\n",
    "\t# Get first h1\n",
    "\ttry:\n",
    "\t\ttitle = soup.h1.string\n",
    "\texcept AttributeError:\n",
    "\t\ttitle = default_value\n",
    "\n",
    "\t# Get next td node after element\n",
    "\ttry:\n",
    "\t\tprice_including_tax = soup.find(text='Price (incl. tax)').findNext('td').string\n",
    "\texcept AttributeError:\n",
    "\t\tprice_including_tax = default_value\n",
    "\n",
    "\t# Get next td node after element\n",
    "\ttry:\n",
    "\t\tprice_excluding_tax = soup.find(text='Price (excl. tax)').findNext('td').string\n",
    "\texcept AttributeError:\n",
    "\t\tprice_excluding_tax = default_value\n",
    "\n",
    "\t# Get next td node after element\n",
    "\ttry:\n",
    "\t\tnumber_available_text = soup.find(text='Availability').findNext('td').string\n",
    "\t\t# Extract number from text\n",
    "\t\tnumber = ''\n",
    "\t\tfor letter in number_available_text:\n",
    "\t\t\tif letter.isdigit():\n",
    "\t\t\t\tnumber += letter\n",
    "\t\tnumber_available = int(number)\n",
    "\texcept AttributeError:\n",
    "\t\tnumber_available = default_value\n",
    "\n",
    "\t# Get next p node after element\n",
    "\ttry:\n",
    "\t\tproduct_description = soup.find(id='product_description').findNext('p').string\n",
    "\texcept AttributeError:\n",
    "\t\tproduct_description = default_value\n",
    "\n",
    "\t# Get next td node after element\n",
    "\ttry:\n",
    "\t\tcategory = book_category\n",
    "\texcept AttributeError:\n",
    "\t\tcategory = default_value\n",
    "\n",
    "\t# Get child who has \"star-rating\" class within \"product_main\" class element\n",
    "\ttry:\n",
    "\t\tstar_rating = soup.find(class_='product_main').find(class_='star-rating')\n",
    "\t\t# Get its second class name which is the number of stars\n",
    "\t\tnumber_of_stars = star_rating['class'][1]\n",
    "\t\t# Use dictionary to get number\n",
    "\t\tequivalent = {'Zero': 0, 'One': 1, 'Two': 2, 'Three': 3, 'Four': 4, 'Five': 5}\n",
    "\t\treview_rating = equivalent[number_of_stars]\n",
    "\texcept AttributeError:\n",
    "\t\treview_rating = default_value\n",
    "\n",
    "\t# Get src attribute of first img\n",
    "\ttry:\n",
    "\t\timg_relative_url = soup.img['src']\n",
    "\t\t# Remove relative elements from path\n",
    "\t\timg_url_list = img_relative_url.split('/')[2:]\n",
    "\t\t# Create absolute URL\n",
    "\t\timage_url = SITE_URL + '/'.join(img_url_list)\n",
    "\n",
    "\t\tdownload_image(image_url, title, category)\n",
    "\texcept AttributeError:\n",
    "\t\timage_url = default_value\n",
    "\n",
    "\treturn {\n",
    "\t\t'universal_product_code': universal_product_code,\n",
    "\t\t'title': title,\n",
    "\t\t'price_including_tax': price_including_tax,\n",
    "\t\t'price_excluding_tax': price_excluding_tax,\n",
    "\t\t'number_available': number_available,\n",
    "\t\t'product_description': product_description,\n",
    "\t\t'category': category,\n",
    "\t\t'review_rating': review_rating,\n",
    "\t\t'image_url': image_url\n",
    "\t}\n",
    "\n",
    "\n",
    "def data_to_csv(data_list, title):\n",
    "\t\"\"\" Extract data from list of products & write them into csv.\n",
    "\n",
    "\tParameters:\n",
    "\t\tdata_list: List of dict as [{key: 'info', ...}, {key: 'info', ...}, {key: 'info', ...}, {key: 'info', ...}]\n",
    "\t\ttitle: Category_name.csv\n",
    "\n",
    "\tReturns:\n",
    "\t\tNone\n",
    "\n",
    "\t\"\"\"\n",
    "\tfile_name = title + '.csv'\n",
    "\t# Open file to write on it\n",
    "\twith open(BOOKS_DIRECTORY + os.sep + file_name, 'w') as file_csv:\n",
    "\t\t# Create writer Object\n",
    "\t\twriter = csv.writer(file_csv, delimiter=',')\n",
    "\t\t# Write data keys as header\n",
    "\t\theader = [*data_list[0]]\n",
    "\t\twriter.writerow(header)\n",
    "\t\t# Write data values as content\n",
    "\t\tfor product in data_list:\n",
    "\t\t\tline = product.values()\n",
    "\t\t\twriter.writerow(line)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c26c1967",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16:15:30\n",
      "http://books.toscrape.com/catalogue/category/books/crime_51/index.html\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "print(datetime.now().strftime(\"%H:%M:%S\"))\n",
    "\n",
    "# Remove all data before starting to get only the newer information\n",
    "os.system('rm -rf ' + DATA_DIRECTORY)\n",
    "\n",
    "# １・SITE_URL変数の中のurlを引数に入れるとそのurlのhrmlコンテンツをgetしてくる\n",
    "site_soup = get_page_content(SITE_URL)\n",
    "\n",
    "# １でgetしたsiteのhtmlをget_categoriesの引数にする\n",
    "#get_categoriesでfindなどを使い欲しい値を取得\n",
    "categories = get_categories(site_soup)\n",
    "\n",
    "# Create books destination directory\n",
    "os.makedirs(BOOKS_DIRECTORY, exist_ok=True)\n",
    "\n",
    "for category in categories:\n",
    "\t# Assign title and URL\n",
    "\tcategory_title = category[0].lower()\n",
    "\n",
    "\tcategory_url = category[1]\n",
    "print(category_url)\n",
    "\n",
    "\t# Create images destination directory\n",
    "\tdestination = IMAGES_DIRECTORY + os.sep + category_title\n",
    "\tos.makedirs(destination, exist_ok=True)\n",
    "\n",
    "\t# Get list of product page URL from category page\n",
    "\tcategory_page_content = get_page_content(category_url)\n",
    "\tproduct_urls = get_product_page_url(category_page_content, category_url)\n",
    "\tproduct_data_list = []\n",
    "\tfor url in product_urls:\n",
    "\t\tpage_content = get_page_content(url)\n",
    "\t\t# Get single product information\n",
    "\t\t# Place product_page_url at first\n",
    "\t\tfirst_info = {'product_page_url': url}\n",
    "\t\tproduct_info = first_info | extract_data(page_content, category_title)\n",
    "\t\t# Add product info to list of multiple product information\n",
    "\t\tproduct_data_list.append(product_info)\n",
    "\t\t# [{key: 'info', ...}, {key: 'info', ...}, {key: 'info', ...}, {key: 'info', ...}]\n",
    "\n",
    "\t###\n",
    "\t# Export data to csv file\n",
    "\t###\n",
    "\tdata_to_csv(product_data_list, category_title)\n",
    "\n",
    "print(datetime.now().strftime(\"%H:%M:%S\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab449dc9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
